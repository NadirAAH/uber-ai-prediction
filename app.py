<<<<<<< HEAD
# ========== IMPORTS ET D√âPENDANCES ==========
# Import des biblioth√®ques principales pour l'application web
import streamlit as st           # Framework web pour cr√©er l'interface utilisateur
import pandas as pd              # Manipulation et analyse des donn√©es
import numpy as np               # Calculs math√©matiques et arrays
import matplotlib.pyplot as plt  # Visualisation de graphiques (matplotlib)
import seaborn as sns           # Visualisation statistique avanc√©e
import plotly.express as px     # Graphiques interactifs Plotly (version express)
import plotly.graph_objects as go  # Graphiques Plotly personnalis√©s
from plotly.subplots import make_subplots  # Cr√©ation de sous-graphiques

# Imports pour le machine learning
from sklearn.model_selection import train_test_split, cross_val_score  # Division donn√©es et validation crois√©e
from sklearn.preprocessing import LabelEncoder, StandardScaler          # Encodage et normalisation
from sklearn.impute import SimpleImputer                               # Imputation des valeurs manquantes
from sklearn.ensemble import RandomForestClassifier                    # Algorithme Random Forest
from sklearn.linear_model import LogisticRegression                    # R√©gression logistique
from sklearn.pipeline import Pipeline                                  # Pipeline pour cha√Æner les transformations
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support  # M√©triques d'√©valuation

# Autres imports utilitaires
import warnings     # Gestion des avertissements
import time        # Gestion du temps (pour les animations)
warnings.filterwarnings('ignore')  # Supprime les avertissements pour interface plus propre

# ========== CONFIGURATION DE LA PAGE STREAMLIT ==========
st.set_page_config(
    page_title="Uber AI Prediction Platform",    # Titre affich√© dans l'onglet du navigateur
    page_icon="üöó",                             # Ic√¥ne dans l'onglet du navigateur
    layout="wide",                               # Utilise toute la largeur de l'√©cran
    initial_sidebar_state="expanded"             # Sidebar ouverte par d√©faut
)

# ========== PALETTE DE COULEURS GLOBALE ==========
# D√©finit les couleurs utilis√©es dans toute l'application pour la coh√©rence visuelle
COLORS = ['#667eea', '#764ba2', '#f093fb', '#f5576c', '#4facfe', '#00f2fe', '#11998e', '#38ef7d']

# ========== CSS STYLING AVANC√â ==========
st.markdown("""
<style>
    /* Import de la police Google Fonts Inter pour un look moderne */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap');
    
    /* Variables CSS pour r√©utiliser facilement les couleurs et styles */
    :root {
        --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);     /* D√©grad√© principal */
        --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);  /* D√©grad√© secondaire */
        --accent-gradient: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);     /* D√©grad√© d'accent */
        --success-gradient: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);    /* D√©grad√© de succ√®s */
        --glass-bg: rgba(0, 0, 0, 0.5);           /* Fond glassmorphism semi-transparent */
        --glass-border: rgba(255, 255, 255, 0.18); /* Bordure glassmorphism */
        --dark-bg: #0a0a0b;                        /* Fond sombre principal */
        --card-bg: rgba(17, 25, 40, 0.75);         /* Fond des cartes avec transparence */
        --text-primary: #ffffff;                   /* Couleur du texte principal */
        --text-secondary: rgba(255, 255, 255, 20); /* Couleur du texte secondaire */
    }
    
    /* Style du conteneur principal de l'application */
    .main .block-container {
        padding-top: 2rem !important;    /* Espacement en haut */
        padding-bottom: 3rem !important; /* Espacement en bas */
        max-width: 95% !important;       /* Largeur maximale */
    }
   
    /* Style de l'application principale */
    .stApp {
        background: var(--dark-bg);      /* Fond sombre */
        /* D√©grad√©s radiaux pour effet visuel subtil */
        background-image: 
            radial-gradient(circle at 25% 25%, rgba(102, 126, 234, 0.1) 0%, transparent 50%),
            radial-gradient(circle at 75% 75%, rgba(118, 75, 162, 0.1) 0%, transparent 50%);
        color: var(--text-primary);      /* Couleur du texte */
        font-family: 'Inter', sans-serif; /* Police moderne */
    }
    
    /* Style pour l'en-t√™te h√©ro */
    .hero-header {
        background: var(--glass-bg);         /* Fond glassmorphism */
        backdrop-filter: blur(20px);         /* Effet de flou d'arri√®re-plan */
        border: 1px solid var(--glass-border); /* Bordure subtile */
        border-radius: 24px;                 /* Coins arrondis */
        padding: 3rem 2rem;                  /* Espacement int√©rieur */
        text-align: center;                  /* Centrage du texte */
        margin-bottom: 3rem;                 /* Marge inf√©rieure */
        animation: slideDown 0.8s ease-out;  /* Animation d'apparition */
        box-shadow: 0 8px 32px rgba(102, 126, 234, 0.2); /* Ombre port√©e */
    }
    
    /* Animation de glissement vers le bas */
    @keyframes slideDown {
        from { transform: translateY(-100px); opacity: 0; } /* Position initiale */
        to { transform: translateY(0); opacity: 1; }        /* Position finale */
    }
    
    /* Style du titre principal */
    .hero-title {
        font-size: clamp(2.5rem, 5vw, 4rem);        /* Taille responsive */
        font-weight: 800;                            /* Poids de la police tr√®s gras */
        background: var(--primary-gradient);         /* D√©grad√© de couleur */
        -webkit-background-clip: text;               /* Application du d√©grad√© au texte */
        -webkit-text-fill-color: transparent;       /* Rend le texte transparent pour voir le d√©grad√© */
        background-clip: text;                       /* Support standard */
        margin-bottom: 1rem;                         /* Marge inf√©rieure */
    }
    
    /* Style du sous-titre */
    .hero-subtitle {
        font-size: 1.3rem;                  /* Taille du texte */
        color: var(--text-secondary);       /* Couleur secondaire */
        margin-bottom: 0.5rem;              /* Marge inf√©rieure */
        font-weight: 300;                   /* Poids l√©ger */
    }
    
    /* Style pour l'auteur */
    .hero-author {
        font-size: 1.1rem;                          /* Taille du texte */
        font-weight: 600;                            /* Poids semi-gras */
        background: var(--accent-gradient);          /* D√©grad√© d'accent */
        -webkit-background-clip: text;               /* Application au texte */
        -webkit-text-fill-color: transparent;       /* Transparence pour le d√©grad√© */
        background-clip: text;                       /* Support standard */
    }
    
    /* Style des cartes de m√©triques */
    .metric-card {
        background: var(--card-bg);                  /* Fond de carte */
        backdrop-filter: blur(20px);                 /* Effet de flou */
        border: 1px solid var(--glass-border);       /* Bordure subtile */
        border-radius: 16px;                         /* Coins arrondis */
        padding: 2rem 1.5rem;                        /* Espacement int√©rieur */
        text-align: center;                          /* Centrage du texte */
        transition: all 0.4s ease;                   /* Transition fluide pour les effets */
        animation: fadeIn 0.6s ease-out;             /* Animation d'apparition */
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);   /* Ombre port√©e */
    }
    
    /* Effet au survol des cartes */
    .metric-card:hover {
        transform: translateY(-8px);                 /* D√©placement vers le haut */
        box-shadow: 0 20px 40px rgba(102, 126, 234, 0.3); /* Ombre plus prononc√©e */
    }
    
    /* Animation de fondu */
    @keyframes fadeIn {
        from { opacity: 0; transform: scale(0.9); }  /* √âtat initial */
        to { opacity: 1; transform: scale(1); }      /* √âtat final */
    }
    
    /* Style des valeurs de m√©triques */
    .metric-value {
        font-size: 2.5rem;                          /* Grande taille */
        font-weight: 800;                            /* Tr√®s gras */
        background: var(--primary-gradient);         /* D√©grad√© */
        -webkit-background-clip: text;               /* Application au texte */
        -webkit-text-fill-color: transparent;       /* Transparence */
        background-clip: text;                       /* Support standard */
        display: block;                              /* Affichage en bloc */
        margin-bottom: 0.5rem;                       /* Marge inf√©rieure */
    }
    
    /* Style des labels de m√©triques */
    .metric-label {
        color: var(--text-secondary);               /* Couleur secondaire */
        font-size: 1rem;                            /* Taille normale */
        font-weight: 500;                           /* Poids moyen */
        text-transform: uppercase;                  /* Majuscules */
        letter-spacing: 1px;                        /* Espacement des lettres */
    }
    
    /* Style des cartes de succ√®s */
    .success-card {
        background: linear-gradient(135deg, rgba(17, 153, 142, 0.2), rgba(56, 239, 125, 0.2)); /* Fond vert */
        border: 1px solid rgba(56, 239, 125, 0.3);  /* Bordure verte */
        border-radius: 16px;                         /* Coins arrondis */
        padding: 2rem;                               /* Espacement */
        backdrop-filter: blur(20px);                 /* Effet de flou */
        animation: fadeIn 0.8s ease-out;             /* Animation */
        box-shadow: 0 8px 32px rgba(56, 239, 125, 0.2); /* Ombre verte */
    }
    
    /* Style des cartes d'avertissement */
    .warning-card {
        background: linear-gradient(135deg, rgba(252, 70, 107, 0.2), rgba(63, 94, 251, 0.2)); /* Fond rouge */
        border: 1px solid rgba(252, 70, 107, 0.3);   /* Bordure rouge */
        border-radius: 16px;                          /* Coins arrondis */
        padding: 2rem;                                /* Espacement */
        backdrop-filter: blur(20px);                  /* Effet de flou */
        animation: fadeIn 0.8s ease-out;              /* Animation */
        box-shadow: 0 8px 32px rgba(252, 70, 107, 0.2); /* Ombre rouge */
    }
    
    /* Style de la liste des onglets */
    .stTabs [data-baseweb="tab-list"] {
        background: var(--glass-bg);                 /* Fond glassmorphism */
        backdrop-filter: blur(20px);                 /* Effet de flou */
        border-radius: 16px;                         /* Coins arrondis */
        padding: 0.5rem;                             /* Espacement */
        border: 1px solid var(--glass-border);       /* Bordure */
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);   /* Ombre */
        gap: 0.25rem;                                /* Espacement entre onglets */
    }
    
    /* Style des onglets individuels */
    .stTabs [data-baseweb="tab"] {
        background: transparent;                     /* Fond transparent */
        border-radius: 12px;                        /* Coins arrondis */
        color: var(--text-secondary);               /* Couleur du texte */
        font-weight: 600;                           /* Poids semi-gras */
        padding: 1rem 2rem;                         /* Espacement */
        transition: all 0.3s ease;                  /* Transition fluide */
        border: none;                               /* Pas de bordure */
    }
    
    /* Effet au survol des onglets */
    .stTabs [data-baseweb="tab"]:hover {
        background: rgba(102, 126, 234, 0.1);       /* Fond l√©ger au survol */
        color: var(--text-primary);                 /* Couleur du texte */
    }
    
    /* Style de l'onglet actif */
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background: var(--primary-gradient);        /* D√©grad√© principal */
        color: white;                               /* Texte blanc */
        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.4); /* Ombre bleue */
    }
    
    /* Style des boutons */
    .stButton > button {
        background: var(--primary-gradient);        /* D√©grad√© de fond */
        border: none;                               /* Pas de bordure */
        border-radius: 12px;                        /* Coins arrondis */
        color: white;                               /* Texte blanc */
        font-weight: 600;                           /* Poids semi-gras */
        padding: 0.75rem 2rem;                      /* Espacement */
        transition: all 0.3s ease;                  /* Transition fluide */
        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.3); /* Ombre */
        font-size: 1rem;                            /* Taille de police */
        text-transform: uppercase;                  /* Majuscules */
        letter-spacing: 1px;                        /* Espacement des lettres */
    }
    
    /* Effet au survol des boutons */
    .stButton > button:hover {
        transform: translateY(-2px);                /* D√©placement vers le haut */
        box-shadow: 0 8px 32px rgba(102, 126, 234, 0.4); /* Ombre plus prononc√©e */
    }
    
    /* Style des en-t√™tes de section */
    .section-header {
        font-size: 2rem;                           /* Grande taille */
        font-weight: 700;                          /* Tr√®s gras */
        color: var(--text-primary);                /* Couleur principale */
        margin-bottom: 2rem;                       /* Marge inf√©rieure */
        position: relative;                        /* Position relative pour le pseudo-√©l√©ment */
        padding-left: 1rem;                        /* Espacement √† gauche */
    }
    
    /* Barre d√©corative avant l'en-t√™te */
    .section-header::before {
        content: '';                               /* Contenu vide pour pseudo-√©l√©ment */
        position: absolute;                        /* Position absolue */
        left: 0;                                   /* Alignement √† gauche */
        top: 0;                                    /* Alignement en haut */
        bottom: 0;                                 /* Alignement en bas */
        width: 4px;                                /* Largeur de la barre */
        background: var(--primary-gradient);       /* Couleur d√©grad√©e */
        border-radius: 2px;                        /* Coins arrondis */
    }
    
    /* Personnalisation de la section pr√©dictive */
    div[data-testid="stHorizontalBlock"] {
        color: #ffcc00 !important;                 /* Couleur jaune vif pour tout le texte */
        font-weight: 600;                          /* Texte en semi-gras */
    }

    /* Labels comme "Lieu de d√©part" */
    div[data-testid="stHorizontalBlock"] label {
        color: #00f2fe !important;                 /* Couleur bleu clair pour les labels */
    }

    /* Valeurs s√©lectionn√©es (ex: Palam Vihar, Jhilmil) */
    div[data-testid="stHorizontalBlock"] .st-h4 {
        color: #38ef7d !important;                 /* Couleur vert n√©on */
        font-size: 1.2rem;                         /* Taille plus grosse */
    }
</style>
""", unsafe_allow_html=True)  # Permet l'utilisation de HTML et CSS dans Streamlit

# ========== FONCTION DE CHARGEMENT ET VALIDATION DES DONN√âES ==========
@st.cache_data  # Cache les donn√©es pour √©viter de les recharger √† chaque fois
def load_and_validate_data():
    """Fonction de chargement avec feedback moderne"""
    from pathlib import Path  # Import pour la gestion des chemins de fichiers
    
    # Chemin principal vers le fichier de donn√©es
    DATA_PATH = "archive/ncr_ride_bookings.csv"  # Chemin relatif depuis la racine
    
    try:
        file_path = Path(DATA_PATH)  # Cr√©ation d'un objet Path
        
        # V√©rification si le fichier existe au chemin principal
        if not file_path.exists():
            # Liste des chemins alternatifs √† essayer
            alternative_paths = [
                "uber/archive/ncr_ride_bookings.csv",
                "ncr_ride_bookings.csv", 
                "archive/ncr_ride_bookings.csv"
            ]
            
            df = None  # Initialisation du DataFrame
            # Tentative de chargement depuis les chemins alternatifs
            for alt_path in alternative_paths:
                try:
                    df = pd.read_csv(alt_path, encoding='utf-8', low_memory=False)  # Chargement CSV
                    st.success(f"Donn√©es charg√©es depuis : {alt_path}")  # Message de succ√®s
                    break  # Sort de la boucle si le chargement r√©ussit
                except:
                    continue  # Passe au chemin suivant si √©chec
            
            # Si aucun fichier n'a √©t√© trouv√©, utilise des donn√©es de d√©monstration
            if df is None:
                st.warning("Utilisation de donn√©es de d√©monstration")  # Message d'avertissement
                return generate_demo_data()  # Appel de la fonction de g√©n√©ration de donn√©es
            return df  # Retourne le DataFrame charg√©
        
        # Chargement depuis le chemin principal si le fichier existe
        df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)
        
        # V√©rification si le DataFrame n'est pas vide
        if df.empty:
            return generate_demo_data()  # Utilise des donn√©es de d√©mo si vide
            
        # Message de succ√®s avec informations sur la taille du dataset
        st.success(f"Dataset charg√© : {df.shape[0]:,} lignes √ó {df.shape[1]} colonnes")
        return df  # Retourne le DataFrame
        
    except Exception as e:  # Gestion des erreurs
        st.error(f"Erreur : {e}")  # Affiche l'erreur
        return generate_demo_data()  # Utilise des donn√©es de d√©mo en cas d'erreur

# ========== FONCTION DE G√âN√âRATION DE DONN√âES DE D√âMONSTRATION ==========
@st.cache_data  # Cache les donn√©es g√©n√©r√©es
def generate_demo_data():
    """G√©n√®re des donn√©es de d√©monstration"""
    np.random.seed(42)  # Fixe la graine al√©atoire pour la reproductibilit√©
    n_samples = 8000    # Nombre d'√©chantillons √† g√©n√©rer
    
    # G√©n√©ration d'une s√©rie de dates avec un intervalle de 2 heures
    dates = pd.date_range('2023-01-01', periods=n_samples, freq='2H')
    
    # Dictionnaire contenant toutes les colonnes avec leurs valeurs g√©n√©r√©es
    data = {
        # Conversion des dates en format string
        'Date': [d.strftime('%Y-%m-%d') for d in dates],
        # Conversion des heures en format string
        'Time': [d.strftime('%H:%M:%S') for d in dates],
        # G√©n√©ration al√©atoire des statuts de r√©servation avec probabilit√©s sp√©cifiques
        'Booking Status': np.random.choice([
            'Success', 'Canceled by Driver', 'Canceled by Customer'
        ], n_samples, p=[0.75, 0.13, 0.12]),  # 75% succ√®s, 13% annul√© conducteur, 12% annul√© client
        # Lieux de d√©part al√©atoires
        'Pickup Location': np.random.choice([
            'Airport', 'Railway Station', 'Metro Station', 'Mall', 'Hospital',
            'Hotel', 'Office Complex', 'Residential Area', 'Tech Park'
        ], n_samples),
        # Destinations al√©atoires
        'Drop Location': np.random.choice([
            'Airport', 'Railway Station', 'Metro Station', 'Mall', 'Hospital',
            'Hotel', 'Office Complex', 'Residential Area', 'Tech Park'
        ], n_samples),
        # Distance de trajet selon une distribution exponentielle (plus r√©aliste)
        'Ride Distance': np.random.exponential(8, n_samples).clip(min=0.5),
        # Valeur de r√©servation selon une distribution gamma
        'Booking Value': np.random.gamma(2, 15, n_samples).clip(min=8),
        # Types de v√©hicules avec probabilit√©s diff√©rentes
        'Vehicle Type': np.random.choice([
            'Mini', 'Economy', 'Premium', 'Auto', 'Electric'
        ], n_samples, p=[0.35, 0.3, 0.2, 0.1, 0.05]),  # Mini le plus fr√©quent, Electric le moins
        # M√©thodes de paiement avec probabilit√©s r√©alistes
        'Payment Method': np.random.choice([
            'UPI', 'Card', 'Cash', 'Wallet', 'Corporate'
        ], n_samples, p=[0.4, 0.3, 0.15, 0.1, 0.05]),  # UPI le plus utilis√©
        # Temps d'attente v√©hicule selon distribution normale
        'Avg VTAT': np.random.normal(7.5, 3.5, n_samples).clip(min=1),
        # Temps d'attente client selon distribution normale
        'Avg CTAT': np.random.normal(4.8, 2.2, n_samples).clip(min=1)
    }
    
    return pd.DataFrame(data)  # Retourne un DataFrame avec les donn√©es g√©n√©r√©es

# ========== FONCTION DE PR√âTRAITEMENT DES DONN√âES ==========
@st.cache_data   # Cache le r√©sultat du pr√©traitement
def preprocess_data_exact_method(df_raw):
    TARGET_COLUMN = "Booking Status"  # D√©finit la colonne cible √† pr√©dire
    
    df_clean = df_raw.copy()  # Cr√©e une copie du DataFrame original
    # Supprime les lignes o√π la colonne cible est manquante
    df_clean = df_clean.dropna(subset=[TARGET_COLUMN])
    
    high_missing_threshold = 0.8  # Seuil pour supprimer les colonnes avec trop de valeurs manquantes
    columns_to_drop = []  # Liste des colonnes √† supprimer
    
    # Identifie les colonnes avec trop de valeurs manquantes
    for col in df_clean.columns:
        if col != TARGET_COLUMN:  # Exclut la colonne cible
            missing_pct = df_clean[col].isnull().sum() / len(df_clean)  # Calcule le pourcentage de valeurs manquantes
            if missing_pct > high_missing_threshold:  # Si > 80% manquant
                columns_to_drop.append(col)  # Ajoute √† la liste de suppression
    
    df_clean = df_clean.drop(columns=columns_to_drop)  # Supprime les colonnes identifi√©es
    
    # Liste des caract√©ristiques l√©gitimes pour le mod√®le
    LEGITIMATE_FEATURES = [
        'Date', 'Time', 'Pickup Location', 'Drop Location',
        'Ride Distance', 'Booking Value', 'Vehicle Type', 
        'Payment Method', 'Avg VTAT', 'Avg CTAT'
    ]
    
    X = df_clean.drop(columns=[TARGET_COLUMN])  # Caract√©ristiques (variables ind√©pendantes)
    y = df_clean[TARGET_COLUMN].copy()          # Variable cible (variable d√©pendante)
    
    # S√©lectionne uniquement les caract√©ristiques disponibles dans le dataset
    available_features = [feat for feat in LEGITIMATE_FEATURES if feat in X.columns]
    X_selected = X[available_features].copy()   # DataFrame avec caract√©ristiques s√©lectionn√©es
    
    # ========== ENGINEERING DES CARACT√âRISTIQUES TEMPORELLES ==========
    # Traitement des colonnes Date et Time si elles existent
    if 'Date' in X_selected.columns and 'Time' in X_selected.columns:
        try:
            # Combine Date et Time en une seule colonne DateTime
            X_selected['DateTime'] = pd.to_datetime(X_selected['Date'] + ' ' + X_selected['Time'])
            # Extrait l'heure de la DateTime
            X_selected['Hour'] = X_selected['DateTime'].dt.hour
            # Extrait le jour de la semaine (0=lundi, 6=dimanche)
            X_selected['DayOfWeek'] = X_selected['DateTime'].dt.dayofweek
            # Extrait le mois
            X_selected['Month'] = X_selected['DateTime'].dt.month
            # Cr√©e une variable binaire pour le weekend (samedi=5, dimanche=6)
            X_selected['IsWeekend'] = (X_selected['DayOfWeek'] >= 5).astype(int)
            
            # Fonction pour cat√©goriser les heures en cr√©neaux temporels
            def get_time_slot(hour):
                if 6 <= hour < 10: return 'Morning_Rush'        # Rush matinal
                elif 10 <= hour < 16: return 'Midday'           # Milieu de journ√©e
                elif 16 <= hour < 20: return 'Evening_Rush'     # Rush du soir
                elif 20 <= hour < 24: return 'Evening'          # Soir√©e
                else: return 'Night_EarlyMorning'               # Nuit/t√¥t le matin
            
            # Applique la fonction de cat√©gorisation des cr√©neaux
            X_selected['TimeSlot'] = X_selected['Hour'].apply(get_time_slot)
            # Supprime les colonnes originales Date, Time et DateTime
            X_selected = X_selected.drop(columns=['Date', 'Time', 'DateTime'])
        except:
            pass  # Ignore les erreurs de traitement temporal
    
    # ========== ENCODAGE DE LA VARIABLE CIBLE ==========
    label_encoder = LabelEncoder()  # Cr√©e un encodeur pour la variable cible
    y_encoded = label_encoder.fit_transform(y)  # Transforme les labels texte en nombres
    
    # ========== ENCODAGE DES VARIABLES CAT√âGORIELLES ==========
    # Identifie toutes les colonnes de type objet (texte)
    categorical_features = X_selected.select_dtypes(include=['object']).columns.tolist()
    X_processed = X_selected.copy()  # Copie des donn√©es pour le traitement
    feature_encoders = {}  # Dictionnaire pour stocker les encodeurs de chaque caract√©ristique
    
    # Encode chaque caract√©ristique cat√©gorielle
    for feature in categorical_features:
        # Remplace les valeurs manquantes par 'MISSING' et convertit en string
        X_processed[feature] = X_processed[feature].fillna('MISSING').astype(str)
        feature_encoder = LabelEncoder()  # Cr√©e un encodeur pour cette caract√©ristique
        # Transforme les valeurs texte en nombres
        X_processed[feature] = feature_encoder.fit_transform(X_processed[feature])
        feature_encoders[feature] = feature_encoder  # Stocke l'encodeur pour utilisation future
    
    # Retourne tous les √©l√©ments n√©cessaires pour le mod√©lisation et la pr√©diction
    return X_processed, y_encoded, label_encoder, feature_encoders, df_clean, available_features

# ========== FONCTION D'ENTRA√éNEMENT DES MOD√àLES ==========
@st.cache_resource  # Cache les mod√®les entra√Æn√©s (plus persistant que cache_data)
def train_models_exact_method(X_processed, y_encoded):
    # ========== DIVISION DES DONN√âES ==========
    try:
        # Tentative de division stratifi√©e (maintient les proportions des classes)
        # V√©rification que chaque classe a au moins 2 √©chantillons pour la stratification
        stratify_param = y_encoded if len(set(y_encoded)) > 1 and min(np.bincount(y_encoded)) >= 2 else None
        X_train, X_test, y_train, y_test = train_test_split(
            X_processed, y_encoded, 
            test_size=0.2,        # 20% pour le test, 80% pour l'entra√Ænement
            random_state=42,      # Graine al√©atoire pour la reproductibilit√©
            stratify=stratify_param  # Maintient les proportions des classes
        )
    except:
        # Division simple sans stratification en cas d'erreur
        X_train, X_test, y_train, y_test = train_test_split(
            X_processed, y_encoded, test_size=0.2, random_state=42
        )
    
    # ========== PIPELINE DE PR√âTRAITEMENT ==========
    preprocessing_pipeline = Pipeline([
        # Imputation des valeurs manquantes par la m√©diane
        ('imputer', SimpleImputer(strategy='median')),
        # Standardisation des variables (moyenne=0, √©cart-type=1)
        ('scaler', StandardScaler())
    ])
    
    # ========== D√âFINITION DES MOD√àLES ==========
    models = {
        # Mod√®le de R√©gression Logistique
        "R√©gression Logistique": Pipeline([
            ('preprocessing', preprocessing_pipeline),  # √âtape de pr√©traitement
            ('classifier', LogisticRegression(
                max_iter=1000,         # Nombre maximum d'it√©rations
                random_state=42,       # Reproductibilit√©
                class_weight='balanced' # Gestion des classes d√©s√©quilibr√©es
            ))
        ]),
        # Mod√®le Random Forest
        "Random Forest": Pipeline([
            ('preprocessing', preprocessing_pipeline),  # √âtape de pr√©traitement
            ('classifier', RandomForestClassifier(
                n_estimators=100,       # Nombre d'arbres dans la for√™t
                random_state=42,        # Reproductibilit√©
                class_weight='balanced', # Gestion des classes d√©s√©quilibr√©es
                n_jobs=-1              # Utilise tous les processeurs disponibles
=======
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Pr√©diction Statuts R√©servation Uber - Portfolio IA",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour am√©liorer l'apparence
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
    }
    .success-metric {
        background: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-metric {
        background: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Charge les donn√©es r√©elles ou g√©n√®re des donn√©es de d√©monstration"""
    try:
        # Tentative de chargement de vos donn√©es r√©elles
        df = pd.read_csv('uber/archive/ncr_ride_bookings.csv')
        st.success("Donn√©es r√©elles charg√©es avec succ√®s!")
        return df
    except FileNotFoundError:
        st.warning("Fichier de donn√©es non trouv√©. Utilisation de donn√©es de d√©monstration.")
        return generate_demo_data()

@st.cache_data
def generate_demo_data():
    """G√©n√®re des donn√©es de d√©monstration r√©alistes"""
    np.random.seed(42)
    n_samples = 10000
    
    # G√©n√©ration de donn√©es synth√©tiques r√©alistes bas√©es sur le contexte Uber
    dates = pd.date_range('2023-01-01', periods=n_samples, freq='H')
    
    data = {
        'Date': [d.strftime('%Y-%m-%d') for d in dates],
        'Time': [d.strftime('%H:%M:%S') for d in dates],
        'Pickup Location': np.random.choice([
            'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
            'Hotel', 'Office Complex', 'Residential Area'
        ], n_samples, p=[0.15, 0.25, 0.12, 0.10, 0.08, 0.10, 0.15, 0.05]),
        'Drop Location': np.random.choice([
            'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
            'Hotel', 'Office Complex', 'Residential Area'
        ], n_samples, p=[0.12, 0.20, 0.15, 0.08, 0.05, 0.08, 0.12, 0.20]),
        'Ride Distance': np.random.exponential(8, n_samples) + 1,  # Distance en km
        'Booking Value': np.random.normal(28, 12, n_samples).clip(min=8),  # Prix en euros
        'Vehicle Type': np.random.choice([
            'Economy', 'Premium', 'Shared', 'Luxury'
        ], n_samples, p=[0.5, 0.25, 0.2, 0.05]),
        'Payment Method': np.random.choice([
            'Card', 'Cash', 'Wallet', 'Corporate'
        ], n_samples, p=[0.6, 0.25, 0.12, 0.03]),
        'Avg VTAT': np.random.normal(7, 3, n_samples).clip(min=1),  # Temps attente v√©hicule
        'Avg CTAT': np.random.normal(4, 2, n_samples).clip(min=1),  # Temps attente client
        'Booking Status': np.random.choice([
            'Success', 'Canceled by Driver', 'Canceled by Customer', 'No Show'
        ], n_samples, p=[0.75, 0.12, 0.10, 0.03])
    }
    
    return pd.DataFrame(data)

@st.cache_data
def preprocess_data(df):
    """Preprocessing complet des donn√©es"""
    df_processed = df.copy()
    
    # Feature engineering temporel
    df_processed['DateTime'] = pd.to_datetime(df_processed['Date'] + ' ' + df_processed['Time'])
    df_processed['Hour'] = df_processed['DateTime'].dt.hour
    df_processed['DayOfWeek'] = df_processed['DateTime'].dt.dayofweek
    df_processed['Month'] = df_processed['DateTime'].dt.month
    df_processed['IsWeekend'] = (df_processed['DayOfWeek'] >= 5).astype(int)
    
    def get_time_slot(hour):
        if 6 <= hour < 10:
            return 'Morning_Rush'
        elif 10 <= hour < 16:
            return 'Midday'
        elif 16 <= hour < 20:
            return 'Evening_Rush'
        elif 20 <= hour < 24:
            return 'Evening'
        else:
            return 'Night_EarlyMorning'
    
    df_processed['TimeSlot'] = df_processed['Hour'].apply(get_time_slot)
    
    # S√©lection des features pertinentes
    features = ['Pickup Location', 'Drop Location', 'Ride Distance', 'Booking Value',
                'Vehicle Type', 'Payment Method', 'Avg VTAT', 'Avg CTAT',
                'Hour', 'DayOfWeek', 'Month', 'IsWeekend', 'TimeSlot']
    
    X = df_processed[features].copy()
    y = df_processed['Booking Status'].copy()
    
    # Encodage des variables cat√©gorielles
    label_encoders = {}
    categorical_features = X.select_dtypes(include=['object']).columns
    
    for col in categorical_features:
        X[col] = X[col].fillna('MISSING')
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        label_encoders[col] = le
    
    # Encodage de la variable cible
    target_encoder = LabelEncoder()
    y_encoded = target_encoder.fit_transform(y)
    
    return X, y_encoded, target_encoder, label_encoders, df_processed

@st.cache_resource
def train_models(X, y):
    """Entra√Æne et √©value les mod√®les de machine learning"""
    # Division train/test stratifi√©e
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
    
    # Pipeline de preprocessing
    preprocessing = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    # Mod√®les √† √©valuer
    models = {
        'Random Forest': Pipeline([
            ('preprocessing', preprocessing),
            ('classifier', RandomForestClassifier(
                n_estimators=100, 
                random_state=42, 
                class_weight='balanced',
                n_jobs=-1
            ))
        ]),
        'Logistic Regression': Pipeline([
            ('preprocessing', preprocessing),
            ('classifier', LogisticRegression(
                max_iter=1000, 
                random_state=42, 
                class_weight='balanced'
>>>>>>> 7c4a6b4d71e4c4f2ff98ea8e61983123f9ea7e9c
            ))
        ])
    }
    
<<<<<<< HEAD
    # ========== ENTRA√éNEMENT ET √âVALUATION DES MOD√àLES ==========
    results = []  # Liste pour stocker les r√©sultats de chaque mod√®le
    for name, model in models.items():  # It√®re sur chaque mod√®le
        model.fit(X_train, y_train)  # Entra√Æne le mod√®le sur les donn√©es d'entra√Ænement
        y_pred = model.predict(X_test)  # Fait des pr√©dictions sur les donn√©es de test
        accuracy = accuracy_score(y_test, y_pred)  # Calcule la pr√©cision
        # Validation crois√©e √† 5 plis pour une √©valuation robuste
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        
        # Stocke tous les r√©sultats du mod√®le
        results.append({
            'model': model,              # Le mod√®le entra√Æn√©
            'name': name,               # Le nom du mod√®le
            'accuracy': accuracy,       # La pr√©cision sur le jeu de test
            'cv_mean': cv_scores.mean(), # Moyenne de la validation crois√©e
            'cv_std': cv_scores.std(),  # √âcart-type de la validation crois√©e
            'predictions': y_pred       # Les pr√©dictions sur le jeu de test
        })
    
    # S√©lectionne le meilleur mod√®le bas√© sur la pr√©cision
    best_model_result = max(results, key=lambda x: x['accuracy'])
    return results, best_model_result, X_train, X_test, y_train, y_test

# ========== FONCTION DE CR√âATION DU TH√àME PLOTLY ==========
def create_modern_plotly_theme():
    """Th√®me Plotly moderne"""
    return {
        'layout': {
            'paper_bgcolor': 'rgba(0,0,0,0)',  # Fond transparent
            'plot_bgcolor': 'rgba(0,0,0,0)',   # Zone de graphique transparente
            'font': {'color': '#ffffff', 'family': 'Inter'}, # Police blanche Inter
            'colorway': COLORS  # Utilise la palette de couleurs globale
        }
    }

# ========== FONCTION PRINCIPALE DE L'APPLICATION ==========
def main():
    # ========== HEADER H√âRO MODERNE ==========
    st.markdown("""
    <div class="hero-header">
        <h1 class="hero-title">Uber AI Prediction Platform</h1>
        <p class="hero-subtitle">Intelligence Artificielle ‚Ä¢ Machine Learning ‚Ä¢ Data Science</p>
        <p class="hero-author">D√©velopp√© par Nadir Ali Ahmed</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ========== SIDEBAR MODERNE ==========
    with st.sidebar:  # Cr√©e la barre lat√©rale
        # En-t√™te de la sidebar avec style
        st.markdown("""
        <div style="text-align: center; padding: 2rem 0;">
            <h2 style="background: linear-gradient(135deg, #667eea, #764ba2); 
                       -webkit-background-clip: text; -webkit-text-fill-color: transparent;
                       font-weight: 800; margin-bottom: 1rem;">
                Mission Control
            </h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Contenu informatif de la sidebar
        st.markdown("""
        **M√©thodologie Avanc√©e**
        
        **Features Intelligence:**
        ‚Ä¢ Variables temporelles d√©riv√©es
        ‚Ä¢ G√©olocalisation optimis√©e  
        ‚Ä¢ Patterns comportementaux
        
        **AI Pipeline:**
        ‚Ä¢ Data Quality Enhancement
        ‚Ä¢ Feature Engineering Automatis√©
        ‚Ä¢ Ensemble Learning
        
        **Mod√®les D√©ploy√©s:**
        ‚Ä¢ Random Forest Optimis√©
        ‚Ä¢ R√©gression Logistique √âquilibr√©e
        """)
    
    # ========== CHARGEMENT AVEC ANIMATION ==========
    with st.spinner('Initialisation du syst√®me AI...'):  # Spinner d'attente
        progress_bar = st.progress(0)  # Barre de progression
        status_text = st.empty()       # Zone de texte pour le statut
        
        # Animation de chargement avec barre de progression
        for i in range(100):
            progress_bar.progress(i + 1)  # Met √† jour la barre de progression
            # Messages de statut selon l'avancement
            if i < 30:
                status_text.text(f'Chargement des donn√©es... {i+1}%')
            elif i < 60:
                status_text.text(f'Preprocessing avanc√©... {i+1}%')
            elif i < 90:
                status_text.text(f'Entra√Ænement des mod√®les... {i+1}%')
            else:
                status_text.text(f'Finalisation... {i+1}%')
            time.sleep(0.01)  # Pause pour l'animation
        
        # Nettoie les √©l√©ments d'animation
        progress_bar.empty()
        status_text.empty()
        
        # ========== CHARGEMENT ET PR√âPARATION DES DONN√âES ==========
        df_raw = load_and_validate_data()  # Charge les donn√©es
        if df_raw is not None:  # V√©rification que le chargement a r√©ussi
            # Pr√©traitement des donn√©es
            X_processed, y_encoded, label_encoder, feature_encoders, df_clean, available_features = preprocess_data_exact_method(df_raw)
            # Entra√Ænement des mod√®les
            results, best_model_result, X_train, X_test, y_train, y_test = train_models_exact_method(X_processed, y_encoded)
        else:
            st.error("√âchec de l'initialisation")  # Message d'erreur
            return  # Sort de la fonction si √©chec
    
    # ========== CREATION DES ONGLETS PRINCIPAUX ==========
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "Dashboard", "Data Science", "AI Models", "Analytics", "Live Prediction"
    ])
    
    # ========== ONGLET 1: DASHBOARD ==========
    with tab1:
        st.markdown('<h2 class="section-header">Executive Dashboard</h2>', unsafe_allow_html=True)
        
        # ========== M√âTRIQUES PRINCIPALES ==========
        col1, col2, col3, col4 = st.columns(4)  # Cr√©e 4 colonnes √©gales
        
        # D√©finition des m√©triques √† afficher
        metrics = [
            ("Observations", f"{len(df_raw):,}", ""),        # Nombre total de lignes
            ("Variables", f"{len(df_raw.columns)}", ""),     # Nombre de colonnes
            ("Taux Succ√®s", f"{(df_raw['Booking Status'] == 'Success').mean()*100:.1f}%", ""), # Pourcentage de succ√®s
            ("Performance IA", f"{best_model_result['accuracy']*100:.1f}%", "") # Performance du meilleur mod√®le
        ]
        
        # Affichage de chaque m√©trique dans sa colonne
        for i, (col, (label, value, icon)) in enumerate(zip([col1, col2, col3, col4], metrics)):
            with col:
                st.markdown(f"""
                <div class="metric-card" style="animation-delay: {i*0.1}s;">
                    <span style="font-size: 3rem; display: block; margin-bottom: 0.5rem;">{icon}</span>
                    <span class="metric-value">{value}</span>
                    <span class="metric-label">{label}</span>
                </div>
                """, unsafe_allow_html=True)
        
        st.markdown("<br>", unsafe_allow_html=True)  # Espace
        
        # ========== VISUALISATIONS ==========
        col1, col2 = st.columns(2)  # Cr√©e 2 colonnes pour les graphiques
        
        with col1:
            st.subheader("Distribution des Statuts")  # Titre du graphique
            status_counts = df_raw['Booking Status'].value_counts()  # Compte les occurrences
            
            # Cr√©ation d'un graphique en secteurs (pie chart)
            fig = go.Figure(data=go.Pie(
                labels=status_counts.index,      # Labels des secteurs
                values=status_counts.values,     # Valeurs des secteurs
                hole=0.6,                        # Cr√©e un donut chart
                marker_colors=COLORS[:len(status_counts)]  # Utilise les couleurs globales
            ))
            
            # Configuration des traces et du layout
            fig.update_traces(textposition='inside', textinfo='percent+label')
            fig.update_layout(
                **create_modern_plotly_theme()['layout'],  # Applique le th√®me moderne
                height=400,    # Hauteur du graphique
                showlegend=False  # Cache la l√©gende
            )
            
            st.plotly_chart(fig, use_container_width=True)  # Affiche le graphique
        
        with col2:
            st.subheader("Performance")  # Titre du graphique
            
            # Donn√©es de performance (en dur pour la d√©mo)
            perf_data = pd.DataFrame({
                'M√©trique': ['Pr√©cision', 'Recall', 'F1-Score', 'Accuracy'],
                'Score': [0.87, 0.82, 0.84, best_model_result['accuracy']]
            })
            
            # Cr√©ation d'un graphique en barres horizontales
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=perf_data['Score'],          # Valeurs sur l'axe X
                y=perf_data['M√©trique'],       # Labels sur l'axe Y
                orientation='h',               # Barres horizontales
                marker_color=COLORS[:len(perf_data)]  # Couleurs
            ))
            
            fig.update_layout(
                **create_modern_plotly_theme()['layout'],
                height=400,
                xaxis_title="Score",      # Titre axe X
                yaxis_title="M√©triques"   # Titre axe Y
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ========== ONGLET 2: DATA SCIENCE ==========
    with tab2:
        st.markdown('<h2 class="section-header">Data Science Lab</h2>', unsafe_allow_html=True)
=======
    results = {}
    for name, model in models.items():
        # Entra√Ænement
        model.fit(X_train, y_train)
        
        # Pr√©dictions
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)
        
        # M√©triques
        accuracy = accuracy_score(y_test, y_pred)
        
        # Validation crois√©e
        try:
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        except:
            cv_scores = np.array([accuracy])  # Fallback
        
        results[name] = {
            'model': model,
            'accuracy': accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'y_test': y_test
        }
    
    return results, X_train, X_test, y_train, y_test

def create_confusion_matrix_plot(y_test, y_pred, target_encoder):
    """Cr√©e une heatmap de la matrice de confusion"""
    cm = confusion_matrix(y_test, y_pred)
    
    fig = px.imshow(
        cm, 
        text_auto=True,
        aspect="auto",
        title="Matrice de Confusion",
        labels=dict(x="Pr√©dictions", y="Vraies Valeurs"),
        x=target_encoder.classes_,
        y=target_encoder.classes_,
        color_continuous_scale="Blues"
    )
    
    return fig

def create_feature_importance_plot(model, feature_names):
    """Cr√©e un graphique d'importance des features pour Random Forest"""
    if hasattr(model.named_steps['classifier'], 'feature_importances_'):
        importance = model.named_steps['classifier'].feature_importances_
        
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importance
        }).sort_values('Importance', ascending=True)
        
        fig = px.bar(
            importance_df, 
            x='Importance', 
            y='Feature',
            orientation='h',
            title="Importance des Features (Random Forest)"
        )
        
        return fig
    return None

def main():
    # Header principal avec style
    st.markdown("""
    <div class="main-header">
        <h1>üöó Pr√©diction des Statuts de R√©servation Uber</h1>
        <p>Projet d'Intelligence Artificielle - Machine Learning</p>
        <p><strong>Par :</strong> Nadir Ali Ahmed | <strong>Portfolio Data Science</strong></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar avec informations du projet
    st.sidebar.markdown("## üìä √Ä Propos du Projet")
    st.sidebar.markdown("""
    **Objectif :** Pr√©dire le statut des r√©servations Uber
    
    **Classes pr√©dites :**
    - ‚úÖ Succ√®s
    - ‚ùå Annul√© par chauffeur
    - ‚ùå Annul√© par client
    - ‚ö†Ô∏è No Show
    
    **Technologies :**
    - Python (Pandas, Scikit-learn)
    - Random Forest, R√©gression Logistique
    - Streamlit, Plotly
    
    **M√©thodologie :**
    1. Analyse exploratoire (EDA)
    2. Feature Engineering
    3. Preprocessing automatis√©
    4. Entra√Ænement de mod√®les
    5. √âvaluation comparative
    """)
    
    # Chargement des donn√©es avec feedback
    with st.spinner('Chargement et preprocessing des donn√©es...'):
        df = load_data()
        X, y, target_encoder, label_encoders, df_processed = preprocess_data(df)
        results, X_train, X_test, y_train, y_test = train_models(X, y)
    
    # Tabs principales de l'application
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà Donn√©es", 
        "üîç EDA", 
        "ü§ñ Mod√®les", 
        "üìä Performance", 
        "üéØ Test Interactif",
        "üìã Rapport Final"
    ])
    
    with tab1:
        st.header("üìà Aper√ßu des Donn√©es")
        
        # M√©triques principales
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Observations", f"{len(df):,}")
        with col2:
            st.metric("Features", f"{len(X.columns)}")
        with col3:
            st.metric("Classes", f"{len(target_encoder.classes_)}")
        with col4:
            success_rate = (df['Booking Status'] == 'Success').mean() * 100
            st.metric("Taux Succ√®s", f"{success_rate:.1f}%")
        
        # √âchantillon des donn√©es
        st.subheader("√âchantillon des donn√©es originales")
        st.dataframe(df.head(10), use_container_width=True)
        
        # Distribution de la variable cible
        st.subheader("Distribution de la variable cible")
        target_dist = df['Booking Status'].value_counts()
        
        col1, col2 = st.columns(2)
        with col1:
            fig = px.pie(
                values=target_dist.values, 
                names=target_dist.index,
                title="R√©partition des Statuts"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = px.bar(
                x=target_dist.index, 
                y=target_dist.values,
                title="Effectifs par Statut",
                labels={'x': 'Statut', 'y': 'Nombre de r√©servations'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Statistiques descriptives
        st.subheader("Statistiques descriptives")
        st.dataframe(df.describe(), use_container_width=True)
    
    with tab2:
        st.header("üîç Analyse Exploratoire des Donn√©es")
>>>>>>> 7c4a6b4d71e4c4f2ff98ea8e61983123f9ea7e9c
        
        col1, col2 = st.columns(2)
        
        with col1:
<<<<<<< HEAD
            st.subheader("Patterns Temporels")
            # V√©rification si la caract√©ristique 'Hour' existe
            if 'Hour' in X_processed.columns:
                # Agr√©gation des donn√©es par heure
                hourly_data = df_clean.groupby(pd.to_datetime(df_clean['Date'] + ' ' + df_clean['Time']).dt.hour).size()
                
                # Graphique lin√©aire avec zone remplie
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=hourly_data.index,    # Heures
                    y=hourly_data.values,   # Nombre de r√©servations
                    mode='lines+markers',   # Ligne avec marqueurs
                    fill='tonexty',         # Remplissage sous la courbe
                    line=dict(color=COLORS[0], width=3),   # Style de ligne
                    marker=dict(size=8, color=COLORS[1])   # Style des marqueurs
                ))
                
                fig.update_layout(
                    **create_modern_plotly_theme()['layout'],
                    height=350,
                    xaxis_title="Heure",
                    yaxis_title="R√©servations"
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("V√©hicules Premium")
            vehicle_dist = df_raw['Vehicle Type'].value_counts()  # Distribution des types de v√©hicules
            
            # Graphique en barres horizontales
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=vehicle_dist.values,  # Valeurs
                y=vehicle_dist.index,   # Types de v√©hicules
                orientation='h',        # Horizontal
                marker_color=COLORS[:len(vehicle_dist)]
            ))
            
            fig.update_layout(
                **create_modern_plotly_theme()['layout'],
                height=350
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ========== ONGLET 3: AI MODELS ==========
    with tab3:
        st.markdown('<h2 class="section-header">AI Models Center</h2>', unsafe_allow_html=True)
        
        st.subheader("Battle des Algorithmes")
        
        # Cr√©ation d'un DataFrame avec les r√©sultats de comparaison
        comparison_data = pd.DataFrame([
            {'Mod√®le': r['name'], 'Accuracy': r['accuracy'], 'CV Mean': r['cv_mean'], 'CV Std': r['cv_std']}
            for r in results
        ])
        
        # Graphique de comparaison des mod√®les
        fig = go.Figure()
        
        for i, model in enumerate(comparison_data['Mod√®le']):
            fig.add_trace(go.Bar(
                name=model,                                    # Nom du mod√®le
                x=[model],                                     # Position X
                y=[comparison_data.iloc[i]['Accuracy']],       # Valeur accuracy
                marker_color=COLORS[i],                        # Couleur
                text=f"{comparison_data.iloc[i]['Accuracy']:.3f}", # Texte affich√©
                textposition='outside'                         # Position du texte
            ))
        
        fig.update_layout(
            **create_modern_plotly_theme()['layout'],
            height=400,
            yaxis_title="Accuracy Score",
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ========== AFFICHAGE DU CHAMPION ==========
        st.markdown(f"""
        <div class="success-card">
            <h3 style="margin-bottom: 1rem;">Champion Model</h3>
            <h2 style="color: #38ef7d; margin-bottom: 0.5rem;">{best_model_result['name']}</h2>
            <p style="font-size: 1.2rem; margin-bottom: 0.5rem;">
                Accuracy: <strong>{best_model_result['accuracy']:.4f}</strong> ({best_model_result['accuracy']*100:.2f}%)
            </p>
            <p>Validation Crois√©e: {best_model_result['cv_mean']:.4f} ¬± {best_model_result['cv_std']:.4f}</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ========== ONGLET 4: ANALYTICS ==========
    with tab4:
        st.markdown('<h2 class="section-header">Advanced Analytics</h2>', unsafe_allow_html=True)
=======
            st.subheader("R√©servations par heure")
            hourly_data = df_processed.groupby('Hour').size()
            fig = px.line(
                x=hourly_data.index, 
                y=hourly_data.values,
                title="Volume de r√©servations par heure",
                labels={'x': 'Heure', 'y': 'Nombre de r√©servations'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Statuts par jour de la semaine")
            days = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
            weekly_data = pd.crosstab(df_processed['DayOfWeek'], df['Booking Status'])
            weekly_data.index = days
            fig = px.bar(weekly_data, title="Statuts par jour de la semaine")
            st.plotly_chart(fig, use_container_width=True)
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.subheader("Distribution des distances")
            fig = px.histogram(
                df, 
                x='Ride Distance', 
                title="Distribution des distances de trajet",
                nbins=50
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col4:
            st.subheader("Valeur moyenne par type de v√©hicule")
            vehicle_stats = df.groupby('Vehicle Type')['Booking Value'].mean().sort_values(ascending=False)
            fig = px.bar(
                x=vehicle_stats.values,
                y=vehicle_stats.index,
                orientation='h',
                title="Valeur moyenne par type de v√©hicule"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Corr√©lations
        st.subheader("Matrice de corr√©lation des variables num√©riques")
        numeric_cols = ['Ride Distance', 'Booking Value', 'Avg VTAT', 'Avg CTAT', 'Hour']
        if all(col in df.columns for col in numeric_cols):
            corr_matrix = df[numeric_cols].corr()
            fig = px.imshow(
                corr_matrix, 
                title="Corr√©lations entre variables num√©riques",
                color_continuous_scale="RdBu_r",
                aspect="auto"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.header("ü§ñ Mod√®les d'Intelligence Artificielle")
        
        st.markdown("""
        ### üõ†Ô∏è M√©thodologie de D√©veloppement
        
        **1. Feature Engineering :**
        - Extraction temporelle : heure, jour semaine, cr√©neaux horaires
        - Variables d√©riv√©es : weekend, rush hours
        - Encodage des variables cat√©gorielles
        
        **2. Preprocessing :**
        - Gestion des valeurs manquantes (m√©diane)
        - Standardisation des features num√©riques
        - Pipeline int√©gr√© pour √©viter le data leakage
        
        **3. Mod√®les test√©s :**
        - **Random Forest** : Ensemble d'arbres de d√©cision
        - **R√©gression Logistique** : Mod√®le lin√©aire probabiliste
        
        **4. Validation :**
        - Division train/test stratifi√©e (80/20)
        - Validation crois√©e 5-fold
        - √âquilibrage des classes (class_weight='balanced')
        """)
        
        # Comparaison des performances
        st.subheader("üèÜ Comparaison des Performances")
        
        model_comparison = []
        for name, result in results.items():
            model_comparison.append({
                'Mod√®le': name,
                'Accuracy': result['accuracy'],
                'CV Mean': result['cv_mean'],
                'CV Std': result['cv_std']
            })
        
        comparison_df = pd.DataFrame(model_comparison)
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(
                comparison_df.style.format({
                    'Accuracy': '{:.4f}',
                    'CV Mean': '{:.4f}',
                    'CV Std': '{:.4f}'
                }),
                use_container_width=True
            )
        
        with col2:
            fig = px.bar(
                comparison_df, 
                x='Mod√®le', 
                y='Accuracy',
                title="Accuracy par mod√®le",
                color='Accuracy',
                color_continuous_scale='viridis'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Meilleur mod√®le
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        st.markdown(f"""
        <div class="success-metric">
            <h4>üèÜ Meilleur Mod√®le : {best_model_name}</h4>
            <p>Accuracy: {results[best_model_name]['accuracy']:.4f} ({results[best_model_name]['accuracy']*100:.2f}%)</p>
        </div>
        """, unsafe_allow_html=True)
    
    with tab4:
        st.header("üìä Analyse D√©taill√©e des Performances")
        
        # S√©lection du meilleur mod√®le
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        best_result = results[best_model_name]
>>>>>>> 7c4a6b4d71e4c4f2ff98ea8e61983123f9ea7e9c
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Matrice de Confusion")
<<<<<<< HEAD
            # Calcul de la matrice de confusion
            cm = confusion_matrix(y_test, best_model_result['predictions'])
            
            # Heatmap de la matrice de confusion
            fig = go.Figure(data=go.Heatmap(
                z=cm,                           # Valeurs de la matrice
                x=label_encoder.classes_,       # Labels X (pr√©dictions)
                y=label_encoder.classes_,       # Labels Y (vraies valeurs)
                colorscale='Viridis',           # √âchelle de couleur
                text=cm,                        # Texte affich√© dans chaque cellule
                texttemplate="%{text}",         # Format du texte
                textfont={"size": 16},          # Taille de police
                showscale=True                  # Affiche l'√©chelle de couleur
            ))
            
            fig.update_layout(
                **create_modern_plotly_theme()['layout'],
                height=400,
                xaxis_title="Pr√©dictions",
                yaxis_title="Vraies Valeurs"
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("M√©triques D√©taill√©es")
            # Calcul des m√©triques d√©taill√©es pour chaque classe
            precision, recall, f1, support = precision_recall_fscore_support(
                y_test, best_model_result['predictions'], average=None
            )
            
            # Cr√©ation du DataFrame des m√©triques
            metrics_data = pd.DataFrame({
                'Classe': label_encoder.classes_,  # Noms des classes
                'Precision': precision,            # Pr√©cision par classe
                'Recall': recall,                  # Rappel par classe
                'F1-Score': f1                     # F1-Score par classe
            })
            
            # Graphique en barres group√©es
            fig = go.Figure()
            
            metric_colors = {'Precision': COLORS[0], 'Recall': COLORS[1], 'F1-Score': COLORS[2]}
            
            # Ajoute une barre pour chaque m√©trique
            for metric in ['Precision', 'Recall', 'F1-Score']:
                fig.add_trace(go.Bar(
                    name=metric,                    # Nom de la s√©rie
                    x=metrics_data['Classe'],       # Classes sur X
                    y=metrics_data[metric],         # Valeurs sur Y
                    marker_color=metric_colors[metric]  # Couleur sp√©cifique
                ))
            
            fig.update_layout(
                **create_modern_plotly_theme()['layout'],
                height=400,
                barmode='group'  # Barres group√©es
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ========== ONGLET 5: PR√âDICTION EN TEMPS R√âEL ==========
    with tab5:
        st.markdown('<h2 class="section-header">Live AI Prediction</h2>', unsafe_allow_html=True)
        
        # Description de la section
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <p style="font-size: 1.2rem; color: rgba(255,255,255,0.7);">
                Testez le mod√®le en temps r√©el avec vos param√®tres personnalis√©s
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # ========== INTERFACE DE SAISIE ==========
        col1, col2, col3 = st.columns(3)  # Trois colonnes pour les inputs
        
        with col1:
            # Extraction des options uniques depuis les donn√©es
            pickup_options = df_clean['Pickup Location'].unique()
            drop_options = df_clean['Drop Location'].unique()
            
            # S√©lecteurs pour les lieux
            pickup = st.selectbox("Lieu de D√©part", pickup_options)
            drop = st.selectbox("Destination", drop_options)
            
        with col2:
            # Options pour v√©hicule et paiement
            vehicle_options = df_clean['Vehicle Type'].unique()
            payment_options = df_clean['Payment Method'].unique()
            
            vehicle_type = st.selectbox("Type de V√©hicule", vehicle_options)
            payment = st.selectbox("Mode de Paiement", payment_options)
            
        with col3:
            # Sliders pour les valeurs num√©riques
            distance = st.slider("Distance (km)", 1.0, 50.0, 12.0)        # Distance du trajet
            booking_value = st.slider("Valeur", 10.0, 500.0, 120.0)       # Valeur de la r√©servation
            hour = st.slider("Heure", 0, 23, 14)                          # Heure de la r√©servation
        
        # ========== BOUTON DE PR√âDICTION ==========
        if st.button("PR√âDIRE LE STATUT"):
            with st.spinner('Intelligence artificielle en action...'):  # Spinner pendant la pr√©diction
                time.sleep(1)  # Pause pour l'effet visuel
                
                # ========== PR√âPARATION DES DONN√âES DE TEST ==========
                test_data = {}  # Dictionnaire pour les donn√©es de test
                
                # Remplissage des donn√©es selon les caract√©ristiques du mod√®le
                for feature in X_processed.columns:
                    if feature == 'Hour':
                        test_data[feature] = hour
                    elif feature == 'Pickup Location':
                        test_data[feature] = pickup
                    elif feature == 'Drop Location':
                        test_data[feature] = drop
                    elif feature == 'Vehicle Type':
                        test_data[feature] = vehicle_type
                    elif feature == 'Payment Method':
                        test_data[feature] = payment
                    elif feature == 'Ride Distance':
                        test_data[feature] = distance
                    elif feature == 'Booking Value':
                        test_data[feature] = booking_value
                    else:
                        test_data[feature] = 0  # Valeur par d√©faut pour les autres caract√©ristiques
                
                # ========== ENCODAGE DES VARIABLES CAT√âGORIELLES ==========
                # Applique les encodeurs pr√©c√©demment entra√Æn√©s
                for col, encoder in feature_encoders.items():
                    if col in test_data and isinstance(test_data[col], str):
                        try:
                            # V√©rifie si la valeur √©tait dans l'entra√Ænement
                            if test_data[col] in encoder.classes_:
                                test_data[col] = encoder.transform([test_data[col]])[0]
                            else:
                                test_data[col] = 0  # Valeur par d√©faut pour les nouvelles cat√©gories
                        except:
                            test_data[col] = 0
                
                # ========== PR√âDICTION ==========
                try:
                    test_df = pd.DataFrame([test_data])  # Conversion en DataFrame
                    prediction = best_model_result['model'].predict(test_df)[0]  # Pr√©diction
                    prediction_proba = best_model_result['model'].predict_proba(test_df)[0]  # Probabilit√©s
                    predicted_class = label_encoder.inverse_transform([prediction])[0]  # Classe pr√©dite
                    confidence = np.max(prediction_proba)  # Confiance maximum
                    
                    # ========== AFFICHAGE DU R√âSULTAT ==========
                    if predicted_class == 'Success':
                        # Carte de succ√®s
                        st.markdown(f"""
                        <div class="success-card" style="text-align: center; margin: 2rem 0;">
                            <h2 style="color: #38ef7d; margin-bottom: 1rem;">SUCC√àS PR√âDIT</h2>
                            <h3 style="margin-bottom: 0.5rem;">R√©servation: {predicted_class}</h3>
                            <p style="font-size: 1.2rem;">Confiance: <strong>{confidence:.1%}</strong></p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        # Carte d'avertissement
                        st.markdown(f"""
                        <div class="warning-card" style="text-align: center; margin: 2rem 0;">
                            <h2 style="color: #fc466b; margin-bottom: 1rem;">RISQUE D√âTECT√â</h2>
                            <h3 style="margin-bottom: 0.5rem;">Statut: {predicted_class}</h3>
                            <p style="font-size: 1.2rem;">Confiance: <strong>{confidence:.1%}</strong></p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # ========== GRAPHIQUE DES PROBABILIT√âS ==========
                    # Cr√©ation du DataFrame des probabilit√©s
                    proba_df = pd.DataFrame({
                        'Statut': label_encoder.classes_,
                        'Probabilit√©': prediction_proba
                    }).sort_values('Probabilit√©', ascending=True)  # Tri par probabilit√©
                    
                    # Graphique en barres des probabilit√©s
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        x=proba_df['Probabilit√©'],      # Probabilit√©s sur X
                        y=proba_df['Statut'],           # Statuts sur Y
                        orientation='h',                # Barres horizontales
                        marker_color=COLORS[:len(proba_df)],  # Couleurs
                        text=[f'{p:.1%}' for p in proba_df['Probabilit√©']],  # Texte des pourcentages
                        textposition='outside'          # Position du texte
                    ))
                    
                    fig.update_layout(
                        **create_modern_plotly_theme()['layout'],
                        title="Distribution des Probabilit√©s",
                        height=300,
                        xaxis_title="Probabilit√©",
                        yaxis_title="Statut"
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"Erreur dans la pr√©diction: {e}")  # Gestion d'erreur
    
    # ========== FOOTER MODERNE ==========
    st.markdown("<br><br>", unsafe_allow_html=True)  # Espacement
    st.markdown("""
    <div style="text-align: center; padding: 3rem 0; border-top: 1px solid rgba(255,255,255,0.1);">
        <h3 style="background: linear-gradient(135deg, #667eea, #764ba2); 
                   -webkit-background-clip: text; -webkit-text-fill-color: transparent;
                   margin-bottom: 1rem;">
            Portfolio Data Science
        </h3>
        <p style="color: rgba(255,255,255,0.7); margin-bottom: 0.5rem;">
            <strong>D√©velopp√© par Nadir Ali Ahmed</strong>
        </p>
        <p style="color: rgba(255,255,255,0.5); font-size: 0.9rem;">
            Intelligence Artificielle ‚Ä¢ Machine Learning ‚Ä¢ Big Data Analytics
        </p>
    </div>
    """, unsafe_allow_html=True)

# ========== POINT D'ENTR√âE DE L'APPLICATION ==========
if __name__ == "__main__":  # V√©rifie si le script est ex√©cut√© directement
    main()  # Lance la fonction principale
=======
            fig = create_confusion_matrix_plot(
                best_result['y_test'], 
                best_result['predictions'], 
                target_encoder
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("M√©triques par Classe")
            report = classification_report(
                best_result['y_test'], 
                best_result['predictions'], 
                target_names=target_encoder.classes_, 
                output_dict=True
            )
            
            report_df = pd.DataFrame(report).transpose().round(3)
            st.dataframe(report_df, use_container_width=True)
        
        # Importance des features (si Random Forest)
        if 'Random Forest' in best_model_name:
            st.subheader("Importance des Features")
            fig = create_feature_importance_plot(best_result['model'], X.columns)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
        
        # Analyse des erreurs
        st.subheader("Analyse des Erreurs")
        cm = confusion_matrix(best_result['y_test'], best_result['predictions'])
        total_errors = len(best_result['y_test']) - cm.trace()
        error_rate = total_errors / len(best_result['y_test'])
        
        st.markdown(f"""
        **Statistiques d'erreur :**
        - Erreurs totales : {total_errors}
        - Taux d'erreur : {error_rate:.3f} ({error_rate*100:.1f}%)
        - Pr√©dictions correctes : {cm.trace()} / {len(best_result['y_test'])}
        """)
    
    with tab5:
        st.header("üéØ Test Interactif du Mod√®le")
        st.markdown("Testez le mod√®le avec vos propres param√®tres et obtenez une pr√©diction en temps r√©el !")
        
        # Interface de test
        col1, col2, col3 = st.columns(3)
        
        with col1:
            pickup = st.selectbox("Lieu de d√©part", [
                'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
                'Hotel', 'Office Complex', 'Residential Area'
            ])
            drop = st.selectbox("Destination", [
                'Airport', 'Downtown', 'Mall', 'Station', 'Hospital', 
                'Hotel', 'Office Complex', 'Residential Area'
            ])
            distance = st.slider("Distance (km)", 1.0, 50.0, 10.0, 0.5)
            booking_value = st.slider("Valeur de la course (‚Ç¨)", 5.0, 100.0, 25.0, 1.0)
            vehicle_type = st.selectbox("Type de v√©hicule", [
                'Economy', 'Premium', 'Shared', 'Luxury'
            ])
        
        with col2:
            payment = st.selectbox("M√©thode de paiement", [
                'Card', 'Cash', 'Wallet', 'Corporate'
            ])
            hour = st.slider("Heure de la r√©servation", 0, 23, 12)
            day_of_week = st.selectbox("Jour de la semaine", [
                'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'
            ])
            avg_vtat = st.slider("Temps d'attente v√©hicule (min)", 1.0, 20.0, 7.0, 0.5)
            avg_ctat = st.slider("Temps d'attente client (min)", 1.0, 15.0, 4.0, 0.5)
        
        with col3:
            st.markdown("### Contexte de la pr√©diction")
            st.info(f"""
            **Trajet :** {pickup} ‚Üí {drop}  
            **Distance :** {distance} km  
            **Valeur :** {booking_value}‚Ç¨  
            **V√©hicule :** {vehicle_type}  
            **Heure :** {hour}h ({day_of_week})
            """)
        
        if st.button("üîÆ Pr√©dire le Statut", type="primary", use_container_width=True):
            # Pr√©paration des donn√©es pour pr√©diction
            day_mapping = {
                'Lundi': 0, 'Mardi': 1, 'Mercredi': 2, 'Jeudi': 3, 
                'Vendredi': 4, 'Samedi': 5, 'Dimanche': 6
            }
            
            def get_time_slot(hour):
                if 6 <= hour < 10:
                    return 'Morning_Rush'
                elif 10 <= hour < 16:
                    return 'Midday'
                elif 16 <= hour < 20:
                    return 'Evening_Rush'
                elif 20 <= hour < 24:
                    return 'Evening'
                else:
                    return 'Night_EarlyMorning'
            
            # Construction de l'√©chantillon de test
            test_data = {
                'Pickup Location': pickup,
                'Drop Location': drop,
                'Ride Distance': distance,
                'Booking Value': booking_value,
                'Vehicle Type': vehicle_type,
                'Payment Method': payment,
                'Avg VTAT': avg_vtat,
                'Avg CTAT': avg_ctat,
                'Hour': hour,
                'DayOfWeek': day_mapping[day_of_week],
                'Month': 6,  # Valeur par d√©faut
                'IsWeekend': 1 if day_mapping[day_of_week] >= 5 else 0,
                'TimeSlot': get_time_slot(hour)
            }
            
            # Encodage des variables cat√©gorielles
            for col, encoder in label_encoders.items():
                if col in test_data:
                    try:
                        if test_data[col] in encoder.classes_:
                            test_data[col] = encoder.transform([test_data[col]])[0]
                        else:
                            test_data[col] = 0  # Valeur par d√©faut
                    except:
                        test_data[col] = 0
            
            # Pr√©diction avec le meilleur mod√®le
            test_df = pd.DataFrame([test_data])
            best_model = results[best_model_name]['model']
            
            try:
                prediction = best_model.predict(test_df)[0]
                prediction_proba = best_model.predict_proba(test_df)[0]
                predicted_class = target_encoder.inverse_transform([prediction])[0]
                
                # Affichage du r√©sultat
                max_proba = np.max(prediction_proba)
                
                if predicted_class == 'Success':
                    st.success(f"üéâ **Pr√©diction : {predicted_class}** (Confiance: {max_proba:.1%})")
                else:
                    st.error(f"‚ö†Ô∏è **Pr√©diction : {predicted_class}** (Confiance: {max_proba:.1%})")
                
                # Graphique des probabilit√©s
                proba_df = pd.DataFrame({
                    'Statut': target_encoder.classes_,
                    'Probabilit√©': prediction_proba
                }).sort_values('Probabilit√©', ascending=True)
                
                fig = px.bar(
                    proba_df, 
                    x='Probabilit√©', 
                    y='Statut',
                    orientation='h',
                    title="Distribution des probabilit√©s",
                    color='Probabilit√©',
                    color_continuous_scale='viridis'
                )
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Erreur lors de la pr√©diction: {e}")
    
    with tab6:
        st.header("üìã Rapport Final du Projet")
        
        # M√©triques de performance finales
        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
        best_accuracy = results[best_model_name]['accuracy']
        
        st.markdown("""
        ## üéØ Objectifs du Projet
        D√©velopper un mod√®le de machine learning capable de pr√©dire avec pr√©cision 
        le statut des r√©servations Uber pour optimiser les op√©rations et am√©liorer 
        l'exp√©rience utilisateur.
        """)
        
        # R√©sultats principaux
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
            <div class="success-metric">
                <h4>üèÜ Mod√®le Final</h4>
                <p><strong>{best_model_name}</strong></p>
                <p>Accuracy: {best_accuracy:.3f} ({best_accuracy*100:.1f}%)</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            total_predictions = len(results[best_model_name]['y_test'])
            correct_predictions = int(best_accuracy * total_predictions)
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìä Performance Test</h4>
                <p>{correct_predictions}/{total_predictions} pr√©dictions correctes</p>
                <p>Sur ensemble de validation</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            cv_mean = results[best_model_name]['cv_mean']
            st.markdown(f"""
            <div class="metric-card">
                <h4>üîÑ Validation Crois√©e</h4>
                <p>Moyenne: {cv_mean:.3f}</p>
                <p>Stabilit√© confirm√©e</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Forces et am√©liorations
        st.markdown("## ‚úÖ Points Forts du Projet")
        st.markdown("""
        - **Feature Engineering avanc√©** : Extraction de patterns temporels pertinents
        - **Pipeline robuste** : Preprocessing automatis√© √©vitant le data leakage
        - **Validation rigoureuse** : Train/test stratifi√© + validation crois√©e
        - **Interface utilisateur** : Application interactive pour tests en temps r√©el
        - **Documentation compl√®te** : Code comment√© et rapport d√©taill√©
        """)
        
        st.markdown("## üîß Am√©liorations Possibles")
        st.markdown("""
        - **Donn√©es externes** : Int√©gration m√©t√©o, trafic, √©v√©nements
        - **Deep Learning** : Test de r√©seaux de neurones pour patterns complexes
        - **Optimisation hyperparam√®tres** : Grid search ou optimisation bay√©sienne
        - **Features g√©ospatiales** : Analyse de la densit√© des zones
        - **Mod√®les ensemblistes** : Stacking ou blending de mod√®les
        """)
        
        st.markdown("## üöÄ Impact Business")
        st.markdown("""
        Ce mod√®le peut √™tre utilis√© pour :
        - **Optimisation des ressources** : Allocation des chauffeurs aux zones √† fort succ√®s
        - **Pr√©vention des annulations** : Identification des r√©servations √† risque
        - **Am√©lioration UX** : Estimation des temps d'attente r√©alistes
        - **Strat√©gie pricing** : Ajustement des tarifs selon probabilit√© de succ√®s
        """)
        
        # Contact et portfolio
        st.markdown("---")
        st.markdown("""
        ### üë®‚Äçüíª Contact & Portfolio
        
        **D√©velopp√© par :** Nadir Ali Ahmed  
        **Email :** [Votre email]  
        **LinkedIn :** [Votre profil LinkedIn]  
        **GitHub :** [Repository du projet]  
        
        *Ce projet fait partie de mon portfolio data science. 
        Il d√©montre mes comp√©tences en machine learning, data preprocessing, 
        et d√©veloppement d'applications interactives.*
        """)

if __name__ == "__main__":
    main()
>>>>>>> 7c4a6b4d71e4c4f2ff98ea8e61983123f9ea7e9c
